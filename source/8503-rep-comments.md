#! https://www.zhihu.com/question/544763123/answer/2588617723

声明: 我没有对DL失去信心,这个问题不是我问的. 我认为这个问题存在更好的表述方式

总结: 复现结果困难, 有一部分因素是来自于"忒修斯之船悖论", 论文,数据集和代码是这艘船非常动态的组成部分,且经常出现不向后兼容的间断点.配上python对于版本和编译的要求比较松散,并不存在一个能保鲁棒复现的机制.

原回答：

当我发现大多数git repo clone下来根本不能跑，依赖也不清晰，test也没有，居然还有几千个星星的时候，我是非常失望的。

虽然我自己的repo也长这个鸟样。。。（doge）

当然，我的信心压根不重要。科技的发展又不会以我的主观意志为转移。看开一点，少吃些垃圾，多消费一些结构优美的构造，就不那么容易抑郁了。比如手撸一个knn，kmeans，pca啥的。

看不懂的东西，原理不明的东西，你完全可以拒绝使用。因为原理不明的东西，用得越多，对自己反噬越大，没有什么意思。如果一项技术只能靠堆卡和算力来证明其效果，那这种玩意就是资本家用来压榨工人的最好工具，最好永远也不要发展出来。

深度学习挺好的，认真复现一下文档记录良好的那些仓库，换个脸，画个画，下下围棋，识别识别语音，加深一下感性理解。不要为了提两个点就去试成百上千个trick，调几十个超参数，逼死自己。因为压根没有必要，这完全属于经验科学的低效研究方式。修修补补的，搞不出什么大新闻，不可能帮助你实现自我价值，也不会给学术界留下什么能够指引后人的方向。

我一直就秉承一条原则，少用自己不理解的东西。因为我只会对自己不理解的东西失去信心，而不会对完全可理解的系统失去信心。


--------

关于评论区几千star为什么跑不起来的问题，我是认为repo的流行程度和代码的可移植性/鲁棒性本来就是完全正交的两个维度，没啥大的相关性。我抨击的是学界凑paper的代码鲁棒性差，这个但凡尝试过复现过paper的知友应该都能理解。（不理解的话多复现几篇paper就能理解了）。更遑论多少paper连代码都没放上来，复现更是困难。硬要说（你复现不出来就是你的问题），我也没啥好杠的，因为这是owner和user之间权责界定的一个问题，不以个人意志为转移。从owner角度当然希望上传代码的责任越少越好，从user的角度当然希望doc和test越多越好，移植越简单越好。所以这根本就不是一个能够归因到个人的一个问题，而是一个鱼和熊掌不可兼得的责任矛盾。

-------

大家有纠结几千star能不能跑的问题，这个问题根源在于python的版本控制和包的版本控制和cuda的版本控制，以及数据集的版本控制上。所以这不是某个repo的问题，而是学术界交换信息的protocol的问题。只要各路journal和会议不强制设定代码和数据交换格式施加外部压力，那这个问题是不会自己把自己解决掉的。

--------

加个例子,今天想用torchtext省事加载一下NLP数据集,结果发现旧版example里面的BucketIterator在最新版本里面都deprecated了... 写python简直就是打移动标靶,不freeze req的话你都不知道自己究竟在干什么...
(3.1k stars)

<https://github.com/pytorch/text/issues/969>

事实上OpenNMT-py直接表示我们要不就直接干掉这个依赖(doge)

<https://github.com/OpenNMT/OpenNMT-py/issues/1956>

总之我的意思是大家不用再刷"几千星是不是你自己的问题?"这类灵魂拷问了. 因为星星再多,或者再优秀的软件也要面对版本控制,这个灵魂拷问, 也会因为不能"向后兼容"的问题而被嫌弃. "不能运行/不能复现"只是一个现象, 欢迎大家对这个现象做更为完善的分析. 但是单纯说"你不行"这种没啥营养的原因我认为是没啥建设性的,所以以后也不会回复了.

------


再加个例子,Bahdanuau2014 <https://github.com/lisa-groundhog/GroundHog>, expriments/nmt/test/test.bash 显然是没有做过ci测试的,依赖的系统状态太多了

私以为,一个好的工作应该让合作者可以清晰地想到:哦我可以把这部分的代码移植到这个问题上看看能不能捕捉到XX现象. 但是糟糕的代码却是会: 哦让我们来看看他究竟是怎么画出他文章里的那几张图的. import failed报错了?没有装torchtext?emm好像没有requirements.txt,也没有conda的yaml,好吧那我按照他的dep装一下.哦又报错了?tensor shape not matched? 哎这奇怪了难道我的torch版本不对? 好的换一个...嗯,tensor not on the same device?难道作者居然是用cpu跑的代码吗?好吧那我帮他们重写一下各个device初始化...我靠,device-side assertion?哪里的index超长了吗? 啥,还没有显存了allocation failed? 

相比之下,有binary的工具真是下下来就能用,我高度推荐对可重复性有追求的研究员们多多创造可复用的binary

--- 

Large image datasets today are a mess

<https://medium.com/@amiralush/large-image-datasets-today-are-a-mess-e3ea4c9e8d22>