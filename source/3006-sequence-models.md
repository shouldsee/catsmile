#! https://zhuanlan.zhihu.com/p/522252647

# 3006: 一些基本的序列模型

CATSMILE静态站页面<http://catsmile.info/3006-sequence-models.html>

## 前言

目标: 借鉴类似于蛋白质MSA->结构思想,引出对序列进行建模的合适方式

动机: NLP里的MLM模型实在是太诡异了,而且在数据量较少时也难以体现Transformer-Attention的优越性(个人实验),鉴于Transformer在NLP和
MSA-Sequence-Sturcture领域都取得了惊人的成绩,所以尝试把MSA的模型
迁移到NLP试试看,希望对小数据建模产生一些积极的影响,并加深对于TransformerAttention的理解

## 蛋白质序列建模的一些方法

同源蛋白序列的对齐在生物信息学里是一个经典问题,在传统语境下具有良好的语境和
研究历史,代表性的方法有hash-based,PSSM,HMM,Dynamic Programming,等等,其目标包括但不限于,Remote Homology Detection, Phylogenetic Reconstruction, Contact Prediction.

## PSSM序列模型: position-specific scoring matrix,序列特化的打分矩阵

PSSM是跟NLP比较接近的一个模型,因此优先介绍.PSSM一般采用 $z_{i}$ 编码一个样板,

$$
\begin{align}
P(Y|Z)&=\prod_i P(y_i|z_{i}) \\
\log P(Y|Z)&=\sum_i \log P(y_i=k|z_{i}) \\
score = \log P(Y|Z)&=\sum_i \mu_{ik}(y_i) \\
\sum_k \exp(\mu_{ik})&=1
\end{align}
$$

其中$\mu_{ik}$是直接影响序列得分的模型参数.这种模型通过一个序列轴向上的filter,找出响应最强的那些序列.可以证明这样的一个分布的概率是归一的

$$
\sum_{y\in Y} P(Y|Z)=1
$$

## PSSM混合模型

由于序列具有多样性,我们可以尝试对不同的PSSM进行混合,从而产生一个
多模态的分布,这意味着我们可以对Z进行建模

$$
P(Y) = \sum_{Z \in \{Z\}} P(Y|Z) P(Z)
$$

特别地,我们考虑经典的unembed分布

$$
P(y_i | z_i ) = {1 \over Z} \exp (\mu_i^T y_i)
$$

并且加入一个位移变量j来节约和复用序列模板

$$
E(Y) = \log P(Y|Z) = \max_{j} \sum_i \log(P(y_i|z_{i-j} ))
$$

其中$\max$ 可以用logsumexp连续化.


此时,加入更多的Z可以充实我们的序列空间,并且后续对P(Z)可以进行重参数化,来表示更多的结构.目前用简单的混合模型来表示P(Z).

约束要求,找到最佳参数$\theta$,来区分噪声分布和数据分布,

$$
-loss(\theta) = \log P (Y_{data}| \theta) - \log P(Y_{data+noise} | \theta)
$$

或者是直接最大化数据的似然

$$
-loss(\theta) = \log P (Y_{data}| \theta)
$$


### 等势面

等势面是描述复杂分布的重要工具.考虑于单字替换$y_{i}\rightarrow \bar y_{i} $,产生的似然变动近似于, $\delta E = \mu_{i}^T (\bar y_{i} - y_{i} )$.这意味着此类PSSM混合模型无法表示序列位置间的相关性,类似于一个短语/词汇记忆模型. 要引入超距作用描述词语间的相关性,还得引入二阶作用项,算一些归一化的常数.

## 简单能量模型

令i个格点的每个位置都为一个d维向量, $X = \{x_{id}\}$,考虑对应PSSM模型的简单能量项

$$
E = \sum_i \mu_i^T x_i \\
p \propto \exp(-\sum_i \mu_i^T x_i)
$$

注意到这里对于$x_i$是不归一的,存在线性缩放问题.PSSM需要在离散态对每个格点的能量做归一化.离散和连续的转化确实是一个令人头疼的问题.只考虑连续问题的化,可以加入正则项避免能量趋于无穷.但回到等势面问题,这类模型不能处理格点之间的协同变化.

$$
E = \sum_i (-\mu_i^T x_i + x_i^T x_i)\\
p \propto \exp(\sum_i (\mu_i^T x_i - x_i^T x_i ))
$$

## 二阶能量模型KID

$$
E = \sum_{ij} \mu_i^T x_i + \mu_j^T x_j + x_i^T W_{ij} x_j
$$

局部hessian 
$$
{ \partial^2 E \over \partial x_i\partial x_j }  = W_{ij}
$$

也就是只要 $\partial(x_i x_j^T) W_{ij}=0$ 那么就能保证E不变. 如果$W_{ij}$是幺正的话会有一些好的性质.但是仍然存在不归一化的问题. 一个简单的办法是
直接把序列的某个位置抠掉然后做前向演化,再计算抠掉的位置的条件分布,基本上是MLM的思想. 这样能够求出某个序列附近的相对概率

$$
p(x_i|X \not  x_i) = { \exp(x_i^T \sum_j W_{ij} x_j )\over { \sum_k \exp ( y_k^T \sum_j W_{ij} x_j} )}
$$

也就是说,用这样一个能量函数去模拟序列的内部的相关性,原则上是可行的.但是对于随机序列直接打分并未做出限制,可能需要取随机序列做一些能量对照来估算配分函数.

### 参数量

如果忽略一阶项,那么每个$W_{ij}$的参数量是$D^2$,对于长度为$I$的序列模型,需要的参数量是$O(I^2 D^2)$,应用线性近似的思想,考虑K个组分,二阶能量可以改写成一个经过了特征抽取后的二阶网络,参数量为$O(2IKD^2)$,我称这种参数化为KID.

$$
y_k = \sum_i Q_{ik} x_i \\
z_k = \sum_i V_{ik}  x_i \\
E = \sum_k y_k^T z_k \\
 = \sum_k (\sum_i x_i^T Q_{ik}^T) (\sum_i V_{ik} x_i)
) 
$$

如果进一步再要求$Q_{ik}$是一个低秩近似,那么参数量可以降低到$O(IKDJ)$,其中J是$Q_{ik}$的秩,这样可以使用更大的D.

实际上,对KID稍做修改,我们可以恢复出一个类似PCA的形式,只要把$y_k,z_k$的维度从D退化成1就可以,得出的参数量就是$O(KID)$

### 优劣

优点是作为浅层模型容易解释,缺点是对变长序列还不能很好处理

OK,该跑几个实验了...

## CBOW模型是一个二阶模型

可以看出,CBOW是一个特殊的二阶模型,参数量为$O(D^2)$,其能量大致为

$$
\begin{aligned}
E &= x_{i-2}^T W x_i + x_{i-1}^T W x_i + x_{i+1}^T W x_i + x_{i+2}^T W x_i \\
  &= (x_{i-2} +x_{i-1} + x_{i+1} +x_{i+2} )^T W x_i 
\end{aligned}
$$


### 对比

从参数量上对比,CBOW,$O(D^2)$可以认为是一个对乱序操作不敏感的,单隐藏单元K=1的特殊KID,$O(KID^2)$.



### 测试例子

(数据来自千言事件抽取数据集)考虑符合 "的一个" 和 "的那个" 的所有序列.
可以发现实体的表征是变长的,因此二阶能量的的形式需要一些思考.从直觉上来讲
$x_i^TWx_j$描述的是一个高维空间里的方向上的旋转.那么确定了"的一个"以后,
前后就出现了可能可以用矩阵描述的一些相关性,

```
[{'text1': 'ru），是南美洲西部的一个国家，北邻厄瓜', 'ys': 51},
 {'text1': '敷市，生于长白山脚下的一个小山村', 'ys': 21},
 {'text1': '了无数女人，而是特么的一个技能就毁了米国', 'ys': 113},
 {'text1': '了支持聚点翻转，其中的一个乐手是我们大同', 'ys': 72},
 {'text1': '妹篇吧，是陈晔的弟弟的一个故事 http', 'ys': 29},
 {'text1': '年，同时也缘于谢霆锋的一个念头', 'ys': 33},
 {'text1': '是全家9个孩子中最小的一个，他拥有一个快', 'ys': 71},
 {'text1': '手，他说：“这是对我的一个鼓励，这张专辑', 'ys': 24},
 {'text1': '2年是牛莉多年努力后的一个丰收年，和张庭', 'ys': 13},
 {'text1': '，创造了中国航空史上的一个又一个“第一”', 'ys': 39},
 {'text1': '款结合了市场主流元素的一个产物，不像是小', 'ys': 107},
 {'text1': '对你，也是一样 这样的一个人，你爱上他的', 'ys': 104},
 {'text1': '安妮》了，是讲他之前的一个恋人的，我听过', 'ys': 235},
 {'text1': '究学习和记忆，在过去的一个世纪里这个领域', 'ys': 123},
 {'text1': '主角，是中国原创动画的一个难忘的经典角色', 'ys': 46},
 {'text1': '范冰冰，真的是很唯美的一个画面呢，话说回', 'ys': 54},
 {'text1': '孩子就叫姚明，很普通的一个名字', 'ys': 89},
 {'text1': '释，认为这是圆了自己的一个梦', 'ys': 48},
 {'text1': '索十二世的父亲是女王的一个情夫近卫军长官', 'ys': 45},
 {'text1': '得山下七海小姐是怎样的一个女孩子呢', 'ys': 180}]

```


但是这种相关性仍然是多峰的,比如"自己的一个"
```
[{'text1': '为解释，认为这是圆了自己的一个梦', 'ys': 46},
 {'text1': '了收买人心，立马就把自己的一个女儿嫁给了', 'ys': 31}]
```

在给定若干词语后,所形成的条件分布,和去除某几个词语后的条件分布,存在着某种对应关系,
从"的一个"->"每一个"对分布造成的影响

```
[{'text1': '可怜的哥哥羽田秀吉，每一个角色在柯南剧中', 'ys': 111},
 {'text1': '温热的歌词，唱出包括每一个对爱怀抱渴求的', 'ys': 61},
 {'text1': '一部讲述每一个男人可能都会面', 'ys': 4},
 {'text1': '慧乔和宋仲基，也祝福每一个为爱而勇敢和成', 'ys': 16},
 {'text1': '5个左右系列剧阵列，每一个都有可能帮助华', 'ys': 114},
 {'text1': '，怅惘，嘟嘴和欣喜，每一个表情都散发着天', 'ys': 63},
 {'text1': '情，杏花仙子的婀娜，每一个精彩人物的塑造', 'ys': 24},
 {'text1': 'V中的女主角那么多，每一个都是比较漂亮的', 'ys': 15},
 {'text1': '妆品行业研制和生产，每一个产品都依照GM', 'ys': 83},
 {'text1': '尽可能再现了抗日战争每一个激动、感人的历', 'ys': 71},
 {'text1': '党员的先锋模范作用和每一个支部的堡垒作用', 'ys': 42},
 {'text1': '们十周年快乐，以后的每一个十周年都要快快', 'ys': 55},
 {'text1': '人物演绎的恰到好处，每一个角色都充满灵气', 'ys': 82},
 {'text1': '音乐表现着电影内容，每一个音符都是戏中演', 'ys': 56},
 {'text1': '自然的出色专注，将让每一个阅读《自然与人', 'ys': 29},
 {'text1': '澄澈明媚的真诚打动了每一个人，他将代表@', 'ys': 90},
 {'text1': '、有大爱，平等地对待每一个学生，打心底里', 'ys': 102},
 {'text1': '就秉承着匠心精神，对每一个镜头严格把控，', 'ys': 33},
 {'text1': '力捧张天爱，估计都是每一个投资人都喜欢的', 'ys': 146},
 {'text1': '每一个历史事件都是命', 'ys': 0}]
```

P(X的一个Z) P(X每一个Z)之间的区别需要用分布间的距离才能描述.
从计算的角度讲,对形如P(XYZ)的序列分布,需要遍历并且组合不同情况下的P(XYZ|Y),
并且加以混合得到P(XYZ)
原则上可以将能量分解为$E(XYZ|Y) = E_Y(X,Z)$的形式,
其中的能量函数都是Y的函数. 因此,要实现不同的分布,就意味着X和Z之间的互作用矩阵是Y的一个参数,否则就无法实现这种动态的模型了

$$
P(X的一个Z)\neq P(X每一个Z)\\
E_Y(X,Z) = (X^T W_Y Z)
$$

从这个角度讲,P(XYZ)的能量函数里必须引入高阶数的张量,否则就无法对观测到的数据进行很好的拟合.如果不存在XYZ之间的三阶作用量,那么P(XYZ|Y1) 和 P(XYZ|Y2)的二阶项目就是恒定的.


巧合的是,Krotov在研究DenseAssociativeMemory的时候也讨论了高次能量项能够提高同等神经元数量网络的记忆容量,
并且对对抗攻击更为鲁棒 {footcite:t}`krotov2016dam` {footcite:t}`krotov2018dam` 

transformers are all you need

```
[{'text1': '后来与徐宗汉成了伉俪的那个湖南人', 'ys': 39},
 {'text1': '稳定的时候，飞飞撒娇的那个声音，实在太好', 'ys': 46},
 {'text1': '歌唱给总是爱的多一点的那个人 想要让心中', 'ys': 160},
 {'text1': '完全不同 至于教育部的那个数据库，写的还', 'ys': 100},
 {'text1': '他爸周异，担任洛阳令的那个', 'ys': 74},
 {'text1': '候是《魔界奇兵》里面的那个猴子的自称就是', 'ys': 19},
 {'text1': '到底柳鹤亭第一次碰见的那个翠衫女到底是谁', 'ys': 66},
 {'text1': '）o泡果奶最近出的那个广告，真的是辣', 'ys': 8},
 {'text1': '剧的武侠宗师，逗留下的那个江湖仍让无数人', 'ys': 115},
 {'text1': '崎，就是给松平叔开车的那个眼镜儿——总之', 'ys': 83},
 {'text1': ' 我想问问亚由美代言的那个巧克力棒是什么', 'ys': 132},
 {'text1': '声音，包括叶清本人演的那个律师... 张', 'ys': 41},
 {'text1': '子……就是你刚才见到的那个女孩，她是我和', 'ys': 20},
 {'text1': '的是苏爽（曾救过枫儿的那个女子）的女儿冷', 'ys': 32},
 {'text1': '跟随到今世不后悔当初的那个举止前世得天下', 'ys': 102},
 {'text1': 'Simon比较喜欢新的那个版本.原因有两', 'ys': 114},
 {'text1': '启刚的妈妈才是更厉害的那个', 'ys': 152},
 {'text1': '后，太喜欢小说中讲述的那个故事，于是找来', 'ys': 29},
 {'text1': '《尚高的那个臭小子》是20', 'ys': 3},
 {'text1': '第70集的预告中出现的那个蓝色背影，就是', 'ys': 12}]
```