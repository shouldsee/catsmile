#! https://zhuanlan.zhihu.com/p/553478979
# 1031: 高斯过程(Gaussian Processes)

[CATSMILE-1031](http://catsmile.info/1031-gp.html)


```{toctree}
---
maxdepth: 4
---
1031-gp.md
```

## 前言

- 目标: 
- 背景与动机: 
    - 在做RNN-VAE的时候需要引入高斯过程相关的隐态和先验.开篇记录一下高斯过程相关的概念
- 结论: 
- 备注: 
- 完成度: 低
- 关键词: 
- 展望方向:
- CHANGELOG:
    - 20220813 INIT


高斯过程是直接由协方差核函数定义的,大意是在某个(连续)结构(时间,空间)上,两点之间的联合分布满足核函数定义的方差的高斯分布. 

高斯过程是一种随机过程,但是不一定符合马尔科夫特性.如果符合马尔科夫
特性,那么一般可以找到对应的卡曼滤波算法来求解隐变量的后验分布.

Zhaozheng指出State space view和global view之间是存在联系的,满足markov特性的GP可以对应到一个SDE结构,也就可以离散化得到一个Kalman Filter

### 特例: 扩散过程

和HMM类似,GP一般关注结构内部的相对关系,而不是绝对的位置,比如说我们可以观察一个高斯扩散核,随着不断地扩散,一个初始位置的delta函数会慢慢平坦下去. 一般来说,隐变量上面会套一个扩散发射核,来处理观测噪声. 考虑如下的漂移过程

$$
P(z_{t+1}|z_t) = {1\over \sigma_z \sqrt{2\pi}}\exp(-{||z_{t+1}-(z_t+\mu)||^2 \over 2\sigma_z^2}) \\
P(y_{t}|z_t) = {1\over \sigma _y\sqrt{2\pi}}\exp(-{||y_{t}-z_t||^2 \over 2\sigma_y^2})
$$

那么在前向后向算法里,我们要做的就是迭代地做一些积分,来求得观测序列的似然. 或者利用图结构,做一些迭代的采样



### 引自 ZhaoZheng

> TL; DR Kalman filters and smoothers can be viewed as solvers for a family of Gaussian process regression models, in particular, Markov Gaussian processes.

> Say, for example, we have a GP regression model

> U(t)Yk∼GP(0,C(t,t′)),=U(tk)+ξk,(1)



> Now, what is the goal of GP regression? The goal is to learn the posterior distribution p(u1:T∣y1:T) jointly for any times t1,…,tT with data y1:T. However, this is known to be expensive, as you need to solve matrix inversion of size T. Also, in practice, we are mostly interested with the marginal posterior p(uk∣y1:T) for k=1,2,…,T instead of the joint one. So, is there any efficient solver for {p(uk∣y1:T)}Tk=1?

## 参考

- ZhaoZheng SE post on GP <https://stats.stackexchange.com/questions/550382/gaussian-process-regression-vs-kalman-filter-for-time-series>

