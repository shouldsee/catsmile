#! https://zhuanlan.zhihu.com/p/569451122

# 8513-从一个小项目讨论全栈机器学习


[CATSMILE-8513](http://catsmile.info/8513-fullstack-ml.html)

```{toctree}
---
maxdepth: 4
---
8513-fullstack-ml.html
```

## 前言

- 目标:
- 背景与动机:
    - 记录一些碎碎念和开发经验
- 结论: 
- 完成度: 
- 备注: 
- 关键词: 
- 展望方向:
- 相关篇目
- 主要参考:
- CHANGLOG:
    - 20220929 INIT

最近在折腾服务器，碰上了如下几个问题。由于现在全栈机器学习的概念并不是太火，但是我在亲身实践的时候又感受到全栈的深刻魅力，因此对当前的工作加以记录。

### 为什么全栈:

因为全栈快，这里指的是对产品的迭代效率，业务的验证进度。
当然，快是有代价的，可能会有鲁棒性，复用性的问题。当然，
全栈到底是为了稳还是快，可以再多探讨一些。

### 问题和结果

1. 通过cli界面调试torch模型进行可视化比较困难，需要借助visdom
进行数据可视化。但是比较多个模型时，业务逻辑会比较复杂，单个
py脚本执行时进行配置和bookkeeping的overhead增加。
    - 学习并理解react前端的类型系统，找到js调用入口。
    - 然后在py里面计算简单的js。插入到按钮onclick的事件中，触发前端向后端的信息发送，启动计算响应周期。
    - 在架设计算周期的时候，学习并应用了pydantic来规范前后端消息格式。
    - （之前）：通过文件形式的层级式持久化，为visdom增加磁盘记忆。

1. 每次要重启supervisord都有点麻烦
    - 引入cesi，顺便解决一些小bug

1. 租的docker只有一个端口，没法跑多个服务
    - 使用frp反向代理多个服务，整合成同一的网页界面
    - 发现仍然难以适配supervisord的默认web界面，可能需要调试，扩展frp或者安装supervisord的相关扩展。

1. 魔改torch模型，在nlp数据集上，通过不同的计算方法，观测不同架构的差异


### 全栈技能: 规划和选型

比如昨天晚上在折腾的nginx和frp问题，调试nginx总不通，容易陷入rewrite循环，主要还是因为不够理解nginx内部的原理以及浏览器缓存的原理。这说明对于原理的知识储备是有效决策的前提。相比之下，由于对于flask的原理和调试方法比较了解，就可以迅速地把cesi魔改成带有base_url的形式，满足使用需求。

但也可以注意到，决策和执行确实是两回事，有可能定好一个开发目标后，一直投入却进展缓慢，这个时候如果回过头来思考，可能一开始的那个目标也不是最适合的

### 全栈技能: 提出并解决问题

全栈工程师需要一个人把PDCA循环跑起来，也就是要合理分配自己的CPU时间，我经常是写写代码，写写markdown，再刷刷github。这是因为尽管现在已经规划好了一条路径，但是搜索信息，或者回顾整理的时候，可以有机会更全面地复盘，并在更加宏观和原理性的层面，而不是执行的细节上，进行总结

### 全栈技能: 资源分配和风险管控

自己租机器，自己做容灾，自己写代码，自己催自己写代码。因为写代码需要时间，但是码而不思则罔。全栈很快会意识到自己的学习能力也是一种需要分配的资源，长期策略一般是按照自己的设计理念去学习整合相关的技术。在这个意义上，全栈的 `开发效率=选择效率*学习效率`，而选择技术
在某种程度上就是在进行架构。

### 全栈不会的东西

实际上，私以为全栈这个理念其实一直存在，它提倡的是学策结合的一种工作和开发模式。或者说，即使人人全栈了以后，仍然会由于人的精力有限而产生分管的区块，但是就不再是为了分工而分工了。从这个意义上讲，全栈精神天生就在对抗由于分工细化而产生的系统性剥削，也在对抗大型系统容易出现的冗余性管理，官僚主义和形式主义。当然，这也只是我的一些观点，希望各位看官斧正！

## 参考

- github frp <https://github.com/fatedier/frp/>
