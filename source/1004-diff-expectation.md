# 1004: 期望函数的梯度计算

- 不使用的后果：哦天哪，你没法往神经网络里塞期望函数了，所以强化学习没戏了，AlphaGo/AlphaZero/AlphaStar集体阵亡。
- 具体形式：TBC
- 背景及展望：
  神经网络的优化过程可以被认为是一个动力过程，但是神经网络的变换过程本身也可以作为一种特殊的动力系统被研究。
  神经网络对于噪音的鲁棒性，并且如何用噪音来进行学习，是一个有意思的生物学相关的方向。
- Motivation: 提高神经网络的表达能力，将其热力学化
- 工具：
  - Attention，MCMC，REINFORCE
  - <https://towardsdatascience.com/attention-in-neural-networks-e66920838742>
  - <http://proceedings.mlr.press/v37/xuc15.pdf>
- 天津包子馅儿：强化学习进阶 第六讲 策略梯度方法
  - <https://hal.archives-ouvertes.fr/hal-02968975/file/Generalized_Stochastic_Backpropagation.pdf>
  - <http://proceedings.mlr.press/v89/xu19a/xu19a.pdf>
